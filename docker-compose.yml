services:
  trainer:
    # Build a thin training image based on the official LLaMA-Factory image
    build:
      context: .
      dockerfile: docker/Dockerfile.train
    image: darvin-translation/trainer:latest
    # Shared memory settings for PyTorch/DataLoader stability
    ipc: host
    shm_size: "16g"
    restart: "no"
    environment:
      # Paths used by train-0/prepare_v2.py (Darvin dataset only)
      - BASE_MODEL_DIR=/tmp/workspace/source_model
      - DARVIN_DATASET_DIR=/tmp/workspace/train/dataset
      - TARGET_MODEL_DIR=/tmp/workspace/target_model
    volumes:
      # Mount the repo to the expected working directory for the scripts
      - ./:/tmp/workspace/train:rw
      # Mount base model directory (must exist on host)
      - ./basemodel:/tmp/workspace/source_model:ro
      # Persist training outputs on host
      - ./output:/tmp/workspace/target_model:rw
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # Run the provided training script (prepare_v2.py is referenced from train-0/ in train.sh)
    command: >-
      bash -lc "\
        set -euo pipefail; \
        cd /tmp/workspace/train/train-0; \
        bash train.sh"
